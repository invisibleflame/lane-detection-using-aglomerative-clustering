# -*- coding: utf-8 -*-
"""Lanedeep

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hy22-BVvU-TZDqPPbOUMlJuEaMMM98vP
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/
import cv2
import os
import matplotlib.pyplot as plt
import numpy as np
# from google.colab.patches import cv2_imshow
# 200, 550], [1080, 550], [0, 720], [1280, 720]
image1 = cv2.imread('cam_img.png')
# s = np.array([[530, 375], [760, 375], [0, 720], [1280, 720]], dtype=np.float32) # old redundant, use below one, keep y 400
# s = np.array([[500, 375], [780, 375], [0, 720], [1280, 720]], dtype=np.float32) #keep y 400
# t = np.array([[0, 0], [1280, 0], [200, 720], [1080, 720]], dtype=np.float32)
(h, w) = (image1.shape[0], image1.shape[1]) #0.625
# source = np.float32([[w // 2 -30 , h * .525], [w // 2 + 30, h * .525], [-100, h], [w + 100, h]])
source = np.float32([[w // 2 -150 , h * .625], [w // 2 + 150, h * .625], [-200, h], [w+200 , h]])
# destination = np.float32([[100, 0], [w - 100, 0], [100, h], [w - 100, h]])
destination = np.float32([[0, 0], [w , 0], [0, h], [w, h]])
M = cv2.getPerspectiveTransform(source, destination)
# M = cv2.getPerspectiveTransform(s, t)
# invM = cv2.getPerspectiveTransform(t,s)
invM = cv2.getPerspectiveTransform(destination,source)
warped = cv2.warpPerspective(image1, M, (image1.shape[1], image1.shape[0]), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)

f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))
#f.tight_layout()
ax1.axis('off')
ax1.imshow(image1)
ax1.set_title('Original', fontsize=18)
ax2.axis('off')
ax2.imshow(warped)
ax2.set_title('Bird\'s eye view', fontsize=18)

from sklearn.cluster import AgglomerativeClustering
algo = AgglomerativeClustering(3,linkage='average', affinity='l2')

import time
img = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)
ret, frame1 = cv2.threshold(img, 180, 256, cv2.THRESH_BINARY)
kernel = np.ones((4,4), np.uint8)
frame1 = cv2.erode(frame1, kernel, iterations=3)
frame1 = cv2.dilate(frame1, kernel, iterations=2)
frame1 = cv2.ximgproc.thinning(frame1, thinningType=cv2.ximgproc.THINNING_GUOHALL)
plt.imshow(frame1)

wheres = np.where(frame1 > 150)
print(wheres[0].shape)
clustered = algo.fit_predict(wheres[1].reshape([-1, 1]))

plt.figure(figsize=(15, 7))
plt.imshow(frame1)
colors = ['r', 'g', 'b']
for i in range(3):
    plt.scatter(wheres[1][clustered == i], wheres[0][clustered == i], label=i, color=colors[i])
plt.show()
plt.show()

